import{_ as a,a as i,o,e,x as t}from"./chunks/framework.Ba_Ek9Jm.js";const b=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"posts/2023/02/a.md","filePath":"posts/2023/02/a.md","lastUpdated":1718173059000}'),s={name:"posts/2023/02/a.md"},n=e("p",null,[e("a",{href:"https://en.wikipedia.org/wiki/Stable_Diffusion",target:"_blank",rel:"noreferrer"},"https://en.wikipedia.org/wiki/Stable_Diffusion"),t(" Stable Diffusion 是 2022 年发布的深度学习文本到图像模型。 它主要用于生成以文本描述为条件的详细图像， 尽管它也可以应用于其他任务，例如修复、外绘制和生成由文本提示引导的图像到图像翻译。 [2]它是由初创公司Stability AI与许多学术研究人员和非营利组织合作开发的。[3]")],-1),r=e("p",null,"稳定扩散是一种潜在扩散模型，是一种深度生成神经网络。 它的代码和模型权重已经公开发布，[4]它可以在大多数配备至少8 GB VRAM的适度GPU的消费硬件上运行。 这标志着与以前的专有文本到图像模型（如DALL-E和Midjourney）的背离，这些模型只能通过云服务访问。[5][6]",-1),l=e("h2",{id:"text-to-img",tabindex:"-1"},[t("text to img "),e("a",{class:"header-anchor",href:"#text-to-img","aria-label":'Permalink to "text to img"'},"​")],-1),d=e("p",null,[e("a",{href:"https://en.wikipedia.org/wiki/Text-to-image_model",target:"_blank",rel:"noreferrer"},"https://en.wikipedia.org/wiki/Text-to-image_model"),t(" 文本到图像模型是一种机器学习模型，它将自然语言描述作为输入，并生成与该描述匹配的图像 。由于深度神经网络的进步，此类模型在 2010 年代中期开始开发。 2022 年， OpenAI 的 DALL-E 2、 谷歌大脑的 Imagen 和 StabilityAI 的 Stable Diffusion 等最先进的文本到图像模型的输出开始接近真实照片和人画艺术的质量。")],-1),_=e("p",null,"文本到图像模型通常结合了语言模型（将输入文本转换为潜在表示）和生成图像模型（生成以该表示为条件的图像）。 最有效的模型通常是在从网络上抓取的大量图像和文本数据上进行训练的。[1",-1),p=[n,r,l,d,_];function c(f,h,m,g,u,k){return o(),i("div",null,p)}const w=a(s,[["render",c]]);export{b as __pageData,w as default};
